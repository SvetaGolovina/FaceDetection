{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=['1.jpg','2.jpg','3.jpg','4.jpg','5.jpg','6.jpg','7.jpg','8.jpg','9.jpg','10.jpg']\n",
    "templates = ['1 face.jpg','1 eyes.jpg', '1 nose.jpg']\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for templ in templates:\n",
    "    tmp = cv2.imread(templ,0)\n",
    "    w, h = tmp.shape[::-1]\n",
    "    for image in images:\n",
    "        img = cv2.imread(image,0)\n",
    "        template_matching(img, tmp, images.index(image), templates.index(templ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(image, template, n, m):\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        img = image.copy()\n",
    "\n",
    "        res = cv2.matchTemplate(img, template, method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        \n",
    "        cv2.rectangle(img, top_left, bottom_right, (255, 0, 0), 2)\n",
    "\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(meth)\n",
    "\n",
    "        figure_name = \"aares-\" + str(n+1) + \"-\" + str(m+1) + \"-\" + str(method)\n",
    "        plt.savefig(figure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face_symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_symmetry(face_cropped):\n",
    "        size = face_cropped.shape\n",
    "        w = int(size[1]/10)\n",
    "        if w < 3:\n",
    "            w = 3\n",
    "        line = w\n",
    "        best_central = [w, 1000000]\n",
    "        while line < size[1] - w:\n",
    "            tmp = 0\n",
    "            for i in range(1, w+1):\n",
    "                for j in range(size[0]):\n",
    "                    tmp += np.abs(int(face_cropped[j][line-i]) - int(face_cropped[j][line+i]))\n",
    "            if tmp < best_central[1]:\n",
    "                best_central = [line, tmp]\n",
    "            line += 2\n",
    "        w1 = int(w/2)\n",
    "        if w1 < 3:\n",
    "            w1 = 3\n",
    "        best_left = [w1, 1000000]\n",
    "        best_right = [best_central[0] + w1, 1000000]\n",
    "        line1 = w1\n",
    "        line2 = best_central[0] + w1\n",
    "        while line1 < best_central[0] - w1 and line2 < size[1] - w1:\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(1, w1+1):\n",
    "                for j in range(int(size[0]/4), int(3*size[0]/4)):\n",
    "                    tmp1 += np.abs(int(face_cropped[j][line1-i]) - int(face_cropped[j][line1+i]))\n",
    "                    tmp2 += np.abs(int(face_cropped[j][line2-i]) - int(face_cropped[j][line2+i]))\n",
    "            if tmp1 < best_left[1]:\n",
    "                best_left = [line1, tmp1]\n",
    "            if tmp2 < best_right[1]:\n",
    "                best_right = [line2, tmp2]\n",
    "            line1 += 2\n",
    "            line2 += 2\n",
    "        return best_central[0], best_left[0], best_right[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viola-Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['1.jpg','3.jpg', '4.jpg', '7.jpg', '8.jpg', '9.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '19.jpg', '20.jpg', '21.jpg', '22.jpg']\n",
    "\n",
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def faceDetection (image, image_gray, n):\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces_rects = face_cascade.detectMultiScale(image_gray, scaleFactor=1.2, minNeighbors=5)\n",
    "\n",
    "    eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    eye_rects = eye_cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=7)\n",
    "\n",
    "    for (x, y, w, h) in faces_rects:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "        borders = int(w/10)\n",
    "        c, l, r = face_symmetry(image_gray[y:y+h, x+borders:x+w-borders])\n",
    "        print(c, l, r)\n",
    "        cv2.line(image, (x+borders+l, y), (x+borders+l, y+h), (255,255,255), 5)\n",
    "        cv2.line(image, (x+borders+c, y), (x+borders+c, y+h), (255,0,255), 5) \n",
    "        cv2.line(image, (x+borders+r, y), (x+borders+r, y+h), (255,255,255), 5)\n",
    "            \n",
    "        for (ex,ey,ew,eh) in eye_rects:\n",
    "            cv2.rectangle(image, (ex,ey), (ex+ew, ey+eh), (255,0,0), 5)\n",
    "    \n",
    "    #convert image to RGB and show image\n",
    "    plt.imshow(convertToRGB(image))\n",
    "    figure_name = \"VJ-\" + str(n+1) + \"-face\"\n",
    "    plt.savefig(figure_name)\n",
    "\n",
    "\n",
    "for img in images:\n",
    "    image = cv2.imread(img)\n",
    "    # Converting to grayscale\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Displaying the grayscale image\n",
    "    plt.imshow(image_gray, cmap='gray')\n",
    "    faceDetection(image, image_gray, images.index(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
